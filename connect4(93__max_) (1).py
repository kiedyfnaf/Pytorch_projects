# -*- coding: utf-8 -*-
"""Connect4(93%"max").ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RiQq5aR9ogLVFf_agUUggeAkCWcEQzxx
"""

import torch
import numpy as np
import os
import random
import math
import time
import matplotlib.pyplot as plt
from torch import nn
import torch.optim as optim
import torch.nn.functional as F

device = "cuda" if torch.cuda.is_available() else "cpu"
PERCENT = 95
GAMES = 1000

# Now this one is undoubtedly the single most frustrating one, okay, so in short its a Connect4 solver,
# for now it only counts 4 upright as a win thats why i called it 'simplified Connect4'.
# Its playing here agains a random opponent, that just puts his "coin" at random, so far
# the best i got is 93% winrate which sounds good but it not even close, cause i want it to win at least 99,8% if these,
# Overall its quite nice but im taking a break from it cause the amount of times i was close to just giving up is insane.
# Here i used a CNN which to my surprise works better than just linear layers, so far it was always worse even in sudoku.
class Connect4Solver(nn.Module):
    def __init__(self):
        super(Connect4Solver, self).__init__()
        self.layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.activation1 = nn.Tanh()
        self.layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.activation2 = nn.ReLU()
        self.layer3 = nn.Linear(64*6*7, 128, bias=True)
        self.activation3 = nn.Tanh()
        self.output = nn.Linear(128, 7, bias=True)
        self.softmax = nn.Softmax(dim=-1)

    # Just a forward, also makes sure shapes are right
    def forward(self, x):
        x = self.activation1(self.layer1(x))
        x = self.activation2(self.layer2(x))
        x = x.view(64 * 7 * 6)
        x = self.activation3(self.layer3(x))
        logits = self.output(x)
        probabilities = logits.view(7)
        probabilities = self.softmax(probabilities)
        return probabilities

    # Picks the column where it thinks thr best move is
    def select_most_confident_cell(self, probabilities):
        max_probability = probabilities.max().item()
        most_confident_cell = probabilities.argmax().item()
        return max_probability, most_confident_cell

    # As the name says, it puts the "coin" in the most confident column
    def fill_the_number(self, most_confident_cell, board, max_probability):
        stop = False
        while stop == False:
          for index in range(6):
            if board[most_confident_cell][5-index] == 0:
              board[most_confident_cell][5-index] = 1
              return board, most_confident_cell, index
              stop = True
              break
          probabilities[most_confident_cell] = 0
          max_probability, most_confident_cell = self.select_most_confident_cell(probabilities)
          if max_probability == 0:
            return board, most_confident_cell, None
        return board, most_confident_cell, index

    # Thats the random enemy, this makes sure it doesnt do some illegal moves along the way
    def random_enemy(self, board):
        options = list(range(7))
        random.shuffle(options)  # Its not the best randomness, but good enough
        x = "None"
        for col in options:
            if torch.min(board[col]) == 0:
                x = col
                break
        if x == "None":
            return board, "None", "None"
        for i_enemy in range(6):
            if board[x][5 - i_enemy] == 0:
                board[x][5 - i_enemy] = 2
                break
        return board, x, i_enemy

    # Checks how many "coins" in a row it has, useful for the "reward" function below
    def in_a_row(self, board, x, most_confident_cell, index):
        count = 0
        if 2 in (board[most_confident_cell][3], board[most_confident_cell][2], board[most_confident_cell][1]):
            count = -1
            return count
        for num in range(4):
            row = most_confident_cell
            col = 5 - index + num
            if col < 0 or col >= len(board[0]):
                return count
            if board[row][col] == 1:
                count += 1
            elif board[row][col] == 2:
                return count
        return count

    # Now this is cool, it checks if a move blocked an opponent streak, this
    # is for the next function, cause i will give it a candy if it breaks the opponent
    # streak at some point.
    def block_in_a_row(self, board, x, most_confident_cell, index):
        count_block = 0
        for num in range(4):
            row = most_confident_cell
            col = 6 - index + num
            if col < 1 or col >= len(board[0]):
                return count_block
            if board[row][col] == 2:  # Player's token
                count_block += 1
            elif board[row][col] == 1:  # Opponent's token
                return count_block  # End streak if opponent token is found
        return count_block

    # This gives a reward or a slap to the model, feel free to change the numbers i just put in what i thought looked ok.
    def reward(self, in_a_row, block_in_a_row, result):
        reward = 0
        if in_a_row == -1:
            reward -= 10
        if in_a_row == 1:
            reward += 4
        elif in_a_row == 2:
          reward += 9
        elif in_a_row == 3:
          reward += 15
        if block_in_a_row == 1:
            reward += 1
        elif block_in_a_row == 2:
          reward += 8
        elif block_in_a_row == 3:
          reward += 15
        if result == "Pytorch":
            reward += 100
        elif result == "Drunken":
            reward -= 100
        elif result == "No winner":
            reward -= 50
        return reward

    # Who won, checks if sb reached 4 in a row in a column
    def is_it_the_end(self, board, x, most_confident_cell, index, i_enemy):
        count, count_enemy= 0, 0
        for num in range(4):
          try:
            if board[most_confident_cell][5-index+num] == 1:
              count += 1
            if count == 4:
              return "Pytorch"
          except IndexError:
            pass
          try:
            if board[x][5-i_enemy+num] == 2:
              count_enemy += 1
            if count_enemy == 4:
              return "Drunken"
          except IndexError:
            pass
        return "No winner"

    # You can change the loss function, i kinda guessed here too, cause its my first time doing a reward system in Pytorch
    def compute_loss(self, reward, epoch):
        if reward > 0:
            loss = max(0, 1 - (reward / 100))  # Reward above 0 decreases loss
        else:
            loss = 1 + abs(reward) / 100  # Negative rewards increase loss
        #epoch_factor = math.sqrt(epoch) / 10  # Adjust the factor as needed
        #loss *= epoch_factor
        return torch.tensor(loss, dtype=torch.float32, requires_grad=True)

model = Connect4Solver()

optimizer = optim.Adam(model.parameters(), lr=0.01)

# Here i run the model with a for loop this time, depends how many games you want it to play, then while it plays, it will print each lost game, and at the end % of wins and losses, and an average loss
# So far the only problem with this one is that it insists on putting "coins" where there arent even 4 free spaces left, i tried to fix this 5+ times, and i just had to take a break,
# cause i was loosing my sanity tyring to figure out why it does it
average = 0
wins = 0
lost = 0
for _ in range(GAMES):
  board = torch.zeros(7,6, device=device)
  board_train = board.reshape(1, 1, 7, 6)
  for epoch in range(50):
    model.train()
    rotated_board = torch.flip(board.T, dims=[1])
    probabilities = model.forward(board_train)
    max_probability, most_confident_cell = model.select_most_confident_cell(probabilities)
    board, most_confident_cell, index = model.fill_the_number(most_confident_cell, board, max_probability)
    if index == None:
      result = "No winner"
      break
    board, x, i_enemy = model.random_enemy(board)
    if x == "None":
      result = "No winner"
      break
    else:
      result = model.is_it_the_end(board, x, most_confident_cell, index, i_enemy)
    in_a_row = model.in_a_row(board, x, most_confident_cell, index)
    block_in_a_row = model.block_in_a_row(board, x, most_confident_cell, index)
    reward = model.reward(in_a_row, block_in_a_row, result)
    board_train = board.view(1,1,7,6)
    if result != "No winner":
      if result == "Pytorch":
        wins += 1
      else:
        print(board)
        lost += 1
      break
    loss = model.compute_loss(reward, epoch)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    model.eval()
  print(f"Game: {_}, loss: {loss}, epoch: {epoch}")
  average += loss.item()
rotated_board = torch.flip(board.T, dims=[1])
print(result)
print(average/GAMES)
print(f"Wins: {100*wins/GAMES}%")
print(f"Lost: {100*lost/GAMES}%")
print(rotated_board)

_

rotated_board

prob = torch.tensor([5,1,2,3,4,3,2])
most = prob.argmax().item()
print(most)

tensor = torch.tensor([0,0,0,0,2,2])
zeros = tensor[tensor == 0]
count_zeros = zeros.numel()
print("Number:", len(tensor) - count_zeros)









