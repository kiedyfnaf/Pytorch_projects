# -*- coding: utf-8 -*-
"""Mnist/CNN(97.5%).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QoWxD0FnzyMbdIOKQ_pkKNI7Inhf8Gh1
"""

import torch
import numpy as np
import pandas as pd
import os
import math
import time
import matplotlib.pyplot as plt
from torch import nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader

mnist_data = pd.read_csv('/content/sample_data/mnist_test.csv')
labels = mnist_data.iloc[:, 0].values
pixels = mnist_data.iloc[:, 1:].values
pixels = pixels / 255.0  # Normalize pixel values to [0, 1]
pixels = pixels.reshape(-1, 28, 28, 1)

# Convert to tensors
tensor_pixels = torch.tensor(pixels, dtype=torch.float32).squeeze(-1).unsqueeze(1)  # Shape: (N, 1, 28, 28)
tensor_labels = torch.tensor(labels, dtype=torch.long)

# Create a dataset and DataLoader with batch size of 32
batch_size = 32
dataset = TensorDataset(tensor_pixels, tensor_labels)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

tensor_pixels[0].shape

device = "cuda" if torch.cuda.is_available() else "cpu"
PERCENT = 95

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        self.activation1 = nn.ReLU()
        self.layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.activation2 = nn.ReLU()
        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)
        self.layer3 = nn.Linear(64 * 14 * 14, 2**8, bias=False)
        self.activation3 = nn.ReLU()
        self.output = nn.Linear(2**8, 10, bias=False)

    def forward(self, x):
        x = self.activation1(self.layer1(x))
        x = self.activation2(self.layer2(x))
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = self.activation3(self.layer3(x))
        x = self.output(x)
        return x

    def predicion(self, x):
        probabilities = torch.softmax(x, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()
        if predicted_class == 0:
          predicted_class = 10
        return predicted_class

model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

losses = []
for epoch in range(10):
  for inputs, targets in data_loader:
      optimizer = optim.Adam(model.parameters(), lr=0.001 * (10**(-epoch)))
      inputs, targets = inputs.to(device), targets.to(device)
      optimizer.zero_grad()
      outputs = model(inputs).squeeze()
      loss = criterion(outputs, targets)
      loss.backward()
      optimizer.step()
      losses.append(loss.item())
      print(f'Epoch {epoch+1}, Loss: {loss.item()}')

correct_predictions = 0
total_samples = 0
losses = []
for epoch in range(5):
    LR= 0.001 * (10**(-epoch))
    for inputs, targets in data_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer = optim.Adam(model.parameters(), lr=LR)
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        _, predicted = torch.max(outputs, 1)
        correct = (predicted == targets).sum().item()  # Count how many were correct
        correct_predictions += correct
        total_samples += targets.size(0)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        losses.append(loss.item())
        print(f'Epoch {epoch+1}, Loss: {loss.item()}')
    accuracy = correct_predictions / total_samples
    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {accuracy*100:.2f}%, Lr: {LR}')
    correct_predictions = 0
    total_samples = 0

plt.plot(range(1, 1566), losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.show()







